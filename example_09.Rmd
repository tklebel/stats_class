---
title: "Example 9"
author: "Thomas Klebel"
date: "9 5 2020"
output: html_document
---

# Task desc

```{r, message=FALSE}
library(tidyverse)
library(patchwork)
theme_set(theme_bw())
grades <- read_csv("data/Mathematics.csv")
```


# (a) Use a regression analysis to estimate a student’s FinalScore.
```{r}
mod1 <- lm(FinalScore ~ ., data = grades)
summary(mod1)
```

```{r}
plot_diag <- function(df) {
  p1 <- ggplot(df, aes(.resid)) +
    geom_histogram(bins = 40)
  

  p2 <- ggplot(df, aes(.fitted, .resid)) +
    geom_point()

  p3 <- ggplot(df, aes(sample = .resid)) +
    geom_qq_line() +
    geom_qq() +
    labs(x = NULL, y = NULL)
  
  p1 / (p2 + p3)
}

broom::augment(mod1) %>% 
  plot_diag()
```

Was ist mit der schrägen Linie in den Residuen?

```{r}
broom::augment(mod1) %>% 
  arrange(.resid) %>% 
  select(FinalScore:G1, .fitted, .resid) %>% 
  head(30) %>% 
  knitr::kable()
```

Fälle mit aus bisher unerklärlichen Gründen finalScore von 0, wo deutlich 
höherer Score vorhergesagt wird.

## i. Which of the features are significant (alpha = 0:05) and how can they be interpreted (interpretation for each significant feature separately!)?
- Age: for each additional year in age, final grade is 
`r abs(coef(mod1)[["age"]])` *lower* (cet. par.)
- Failures: for each additional past failure, final grade is 
`r abs(coef(mod1)[["failures"]])` *lower* (cet. par.)
- Absences: for each additional absence, final grade is 
`r coef(mod1)[["absences"]]` *higher* (cet. par.). this is a bit 
counter-intuitive.
- G1: for each additional point in the first period grade, final grade is 
`r coef(mod1)[["G1"]]` *higher* (cet. par.).

```{r, message=FALSE}
ggplot(grades, aes(absences, FinalScore)) +
  geom_jitter() +
  geom_smooth() +
  geom_smooth(method = "lm", se = FALSE, colour = "red")

grades %>% 
  filter(FinalScore > 0) %>% 
  ggplot(aes(absences, FinalScore)) +
  geom_jitter() +
  geom_smooth()
```


## ii. By how much is the FinalScore of male students in school ‘MS‘ higher/lower than that of male in school ‘GP‘ provided that the other features remain unchanged?
Final score is `r coef(mod1)[["schoolMS"]]` higher.

## iii. By how much is the FinalScore of male students in school ‘MS‘ higher/lower than that of female in school ‘GP‘ provided that the other features remain unchanged?
```{r}
coef(mod1)[["schoolMS"]] + coef(mod1)[["sexM"]]
```



## iv. By how much does the FinalScore change if the first period grade ‘G1‘ changes by 5 units?
```{r}
coef(mod1)[["G1"]] * 5
```


## v. How large is the estimated FinalScore of a male student in school ‘MS‘ at age 17 who has chosen this school because of reputation, never consumes alcohol on weekends, but has 50 absences and no failures, and a first period grade of 10?
```{r}
pred_base <- data.frame(
  sex = "M",
  school = "MS",
  age = 17,
  reason = "reputation",
  Walc = 0,
  absences = 50,
  failures = 0,
  G1 = 10
)

first_pred <- predict(mod1, newdata = pred_base)
first_pred
```


## vi. By how much does the FinalScore change if ‘failures‘ increase by 2 units
```{r}
second_pred <- pred_base %>% 
  mutate(failures = failures + 2) %>% 
  predict(mod1, newdata = .)
second_pred

# alternative
coef(mod1)[["failures"]] * 2

second_pred - first_pred
```
FinalScore is lower

## vii. How large is R2?
```{r}
summary(mod1)$r.squared
```

## viii. Determine the 95% confidence interval for the parameter of age.
```{r}
confint(mod1)
```


```{r}
# calculate conf.int by hand
# get coefficient
beta <- coef(mod1)[["age"]] 

# get t value
t_value <- qt(.975, nrow(grades) - length(coef(mod1)))
# caution: value in output is test-statistic for whether beta == 0.
# we need theoretical quantile for our conf.int
# # degrees of freedom: n - k - 1 with k = number of variables in model

std_dev <- summary(mod1)$coefficients["age", "Std. Error"]

# lower
beta - t_value * std_dev

# upper
beta + t_value * std_dev
```


# (b) Estimate a new regression model with the same features and the following additional features:
i. failures2
ii. log1p(absences)
iii. interaction of absences and failures

```{r}
mod2 <- update(mod1, . ~ . + I(failures^2) + log1p(absences) + absences:failures)
summary(mod2)
```




# i. What is R2 now?
```{r}
summary(mod2)$r.squared
```

# ii. How does the FinalScore change, if failures change by 1 unit while the other features remain unchanged?
# iii. How does the FinalScore change, if absences change by 1 unit while the other features remain unchanged?
```{r}
failres_absences <- pred_base %>% 
  mutate(failures = list(0:3),
         absences = list(c(0, 5, 10, 20, 50))) %>% 
  unnest(failures) %>% 
  unnest(absences) %>% 
  broom::augment(mod2, newdata = .) %>% 
  select(failures, absences, .fitted) %>% 
  mutate(diff = .fitted - lag(.fitted),
         diff = case_when(failures == 0 ~ NA_real_,
                          TRUE ~ diff)) %>% 
  arrange(absences)

failres_absences %>% 
  knitr::kable()
```




# iv. How can we interpret the interaction term? Is it significant and what does this mean?
It is significant.

```{r}
pred_base %>% 
  mutate(absences = list(seq(0, 93, by = 5)),
         failures = list(0:3)) %>% 
  unnest(failures) %>% 
  unnest(absences) %>% 
  broom::augment(mod2, newdata = .) %>% 
  ggplot(aes(absences, .fitted, colour = as.factor(failures))) +
  geom_line() +
  geom_point()
```


```{r}
max(grades$absences)
```


# v. How large is the estimated FinalScore of a male student in school ‘MS‘ at age 17 who has chosen this school because of reputation, never consumes alcohol on weekends, but has 50 absences and no failures, and a first period grade of 10?
```{r}
third_pred <- predict(mod2, newdata = pred_base)
third_pred
first_pred - third_pred
```
Der vorhergesagte Wert ist niedriger als beim ersten Modell.

# vi. How large is the standard deviation ? Is it smaller or larger than in the previous model?
```{r}
summary(mod1)$sigma
summary(mod2)$sigma
```

Kleiner.

### Fehlspezifikation beheben
```{r}
clean_data <- grades %>% 
  filter(FinalScore > 0)

mod3 <-  update(mod2, data = clean_data)

summary(mod3)

broom::augment(mod3) %>% 
  plot_diag()

mod1_rev <-  update(mod1, data = clean_data)
AIC(mod1_rev, mod3)
summary(mod1_rev)
```


# (c) Find a quantile regression for the quantiles 0.05, 0.25, 0.5, 0.75, 0.95. How can we interpret the results? Is a quantile regression justified?
```{r, message=FALSE}
library(quantreg)
mod_quant <- rq(FinalScore ~ ., tau = c(.05, .25, .5, .75, .95), data = grades)
summary(mod_quant)
```

