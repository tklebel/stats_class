---
title: "Example 1"
output: html_document
---

```{r, echo=FALSE, message=FALSE}
library(tidyverse)
extrafont::loadfonts(device = "win")
theme_set(theme_bw())
```

# Task description
For reasons of budget planning a company needs to estimate the cost of product launch several
years in advance. For this purpose the cost of past product launches is estimated by means of a
regression analysis. For 5 products the cost (y) depending on the number of competing’ products
(x) was:


```{r}

df <- tibble(
  x = c(1, 2, 6, 7, 8),
  y = c(5, 5.5, 7, 7, 10)
)
```

# Task (a) What is the regression model like and what assumptions are made?

$cost = \alpha + \beta_1*\text{no. of competing products} + \epsilon$

ABC Annahmen 

### A-Annahmen: Aussage über Art des Zusammenhanges

- y = b0 + b1x1 + b2x2 -> linearer Zusammenhang
- all Variable sind im Modell (kein Bias)
- bj sind konstant (nicht abhängig von x, also keine Strukturbrüche)

### B-Annahmen: Spezifikation des Störterms 

- Erwartungswert ist 0 (kein Bias)
- Konstante Varianz (Homoskedastizität)
- Cov(Ei, Ej) = 0 -> Keine Zeitabhängig


### C-Annahmen: Spezifikation der Variablen

- X Achse gibt es keine Zufallsvariable (wir geben vor, was wir untersuchen wollen, macht die Herleitung leichter) 
- Varianz x (sx^2) darf nicht 0 sein. Wenn es nur ein x gibt, kann man keine Gerade legen.


### BUE 
wenn zusätzlich Störterm normalverteilt ist, mit E - N(0,sigma)




# Task (b) Determine the parameters of the model!




Do it manually:
```{r}
covariance <- df %>% 
  mutate(x_var = (x - mean(x)),
         y_var = (y - mean(y))) %>% 
  summarise(cov = sum(x_var*y_var)/(length(x) - 1)) %>% 
  pull(cov)

beta1 <- cov(df$x, df$y)/var(df$x)
beta0 <- mean(df$y) - beta1 * mean(df$x)
paste("beta =", round(beta1, 4))
paste("intercept =", round(beta0, 4))

```




# Subtask (c) Draw a scatterplot, the regression line and the residuals!

```{r}
df <- df %>% 
  mutate(pred = beta0 + beta1 * x,
         resid = pred - y,
         ymax = pmax(y, pred),
         ymin = pmin(y, pred))

ggplot(df, aes(x, y)) + 
  geom_point() +
  geom_abline(slope = beta1, intercept = beta0) +
  geom_linerange(aes(y = y, ymin = ymin, ymax = ymax))
```


# Task (d) Estimate the variance of the error term!
```{r}
# calculate residuals
error_var <- df %>% 
  mutate(y_pred = beta0 + beta1 * x,
         residuals_squared = (y - y_pred)^2) %>% 
  summarise(var_std_err = sum(residuals_squared) * 1/(length(x) - 2))
error_var
```



# Task (e) Find the p-value of the parameter beta!
```{r}
# calculate standard dev for beta (auer 6.1.3)
# calculate sum of squared distance (summe quadratischer abweichungen)
s_xx <- df %>% 
  mutate(s_xx = (x - mean(x))^2) %>% 
  summarise(s_xx = sum(s_xx)) %>% 
  pull(s_xx)
s_xx

# find standard error of beta coef
se_beta = sqrt(error_var$var_std_err/s_xx)
se_beta

# find t value
t_value <- beta1 / se_beta
t_value

# p value (twice, because we have two tails)
dt(t_value, nrow(df) - 2 - 1) * 2
```


# Task (f) Find the confidence intervall for the parameter beta!
```{r}
# auer formula 5.17

# t-quantile
t_quantile <- qt(1 - .05/2, nrow(df) - 2)

# upper 
beta1 + t_quantile * se_beta
# lower
beta1 - t_quantile * se_beta
```


# Task (g) Determine an appropriate measure for goodness of fit!
```{r}
df %>% 
  mutate(y_pred = beta0 + beta1  * x,
         explained_var = (y_pred - mean(y))^2,
         total_var = (y - mean(y))^2) %>% 
  summarise(
    r_squared = sum(explained_var) / sum(total_var)
  )
```


# Task (h) Predict the cost for x = 10!
```{r}
beta0 + beta1 * 10
```

# Task (i) Find the prediction intervall at x = 10 and interpret the result obtained!
```{r}
# source: auer p 125, formula 7.5
# error_var * [1 + 1/n + (x  - mean(x))^2 / var_x]
err_var <- error_var$var_std_err
error_at_10 <- err_var * (1 + 1/nrow(df) + (10 - mean(df$x))^2 / s_xx)

pred_10 <- beta0 + beta1  * 10


# upper
pred_10 + error_at_10

# lower
pred_10 - error_at_10
```


```{r}
tibble(
  x = -5:15
) %>% 
  mutate(pred = beta0 + beta1  * x,
         pred_interval_error = err_var * (1 + 1/21 + (x - mean(x))^2 / var(x)),
         lower = pred - pred_interval_error,
         upper = pred + pred_interval_error) %>% 
  pivot_longer(c(pred, lower, upper)) %>% 
  ggplot(aes(x, value, colour = name)) +
  geom_line() +
  labs(colour = NULL, y = "y")
```


# correct solution
```{r}
my_mod <- lm(y ~ x, data = df)
summary(my_mod)
```
