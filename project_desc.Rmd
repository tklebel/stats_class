---
title: "Predicting House Prices"
author: "Thomas Klebel"
date: "25 6 2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, dev = "cairo_pdf")
extrafont::loadfonts()

```


# Aufgabenstellung und Herangehensweise
Aufgabe ist es, den Verkaufspreis von Häusern auf Basis einer Reihe an 
Prädiktoren vorherzusagen. Das konkrete Beispiel ist ein bekanntes Problem des
maschinellen Lernens (siehe [hier](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview).

In dieser Projektarbeit möchte ich die Chance nutzen, um fortschrittlichere
Techniken zu erlernen und anzuwenden, die üblicherweise für solche Probleme
verwendet werden. Der Einfachheit halber beschränke ich mich darauf mittels 
Kreuzvalidierung (mit Hilfe des `caret`-packages) drei Modelle zu vergleichen: 

- ein klassisches lineares Regressionsmodell
- ein mittels Lasso geschätzes Modell
- ein mittels elastic net geschätztes Modell

Auf noch kompliziertere Herangehensweisen (stacking) wird verzichtet.


# Exploration
```{r, message=FALSE}
library(tidyverse)
library(visdat)
library(caret)

theme_set(hrbrthemes::theme_ipsum(base_family = "Hind"))

house_data <- read_csv("data/Dataset_HousePrices.csv")
house_train <- house_data %>% 
  filter(!is.na(SalePrice))
house_predict <- anti_join(house_data, house_train)
```

Wichtige Voraussetzung für eine brauchbare Vorhersage ist die korrekte 
Vorbereitung der Variablen. Dabei müssen folgende Probleme behandelt werden:

- Fehlende Werte (-> imputation)
- Kategoriale Prädiktoren (-> dummy codierung)
- fehlende Korrelation mit der Zielvariable
- Multikollinearität
- Nicht-lineare Effekte (Transformation)

Nachdem im vorliegenden Fall eine möglichst genaue Vorhersage das Ziel ist, 
kann die Interpretierbarkeit des Modells hintangestellt werden.

Im Folgenden wird zuerst eine Übersicht aller Variablen dargestellt, bevor
jeder der Prädiktoren einzeln untersucht wird.

```{r, fig.width=15}
vis_dat(house_train)
```

Drei Erkenntnisse lassen sich aus dieser Grafik ziehen:

- Es gibt einerseits metrische und andererseits kategoriale Prädiktoren
- Nur wenige der Variablen weisen fehlende Werte auf.
- Zwei der Variablen haben einen hohen Anteil fehlender Werte (Alley & PoolQC). 
Hierbei handelt es sich um fehlenden Werte vom Typ MAR: Häuser ohne Pool oder
ohne Zugang via einer Alley haben hier keine Daten. Dies lässt sich leicht durch
umkodieren beheben. Möglicherweise trifft ein selbes Muster auch auf andere 
Variablen mit fehlenden Werten zu.

```{r}
house_train %>% 
  select_if(~any(is.na(.x))) %>% 
  vis_miss(sort_miss = TRUE)
```

Bei den Variablen PoolQC, Alley, GarageQual und GarageCond steht ein fehlender
Wert jeweils für die fehlende Eigenschaft. Hier kann umkodiert werden. Die 
fehlenden Werte in LotFrontage lassen sich nicht durch LotConfig oder andere
Variablen erklären, und werden daher imputiert. Selbiges gilt für die Variablen
zu Masonry veneer und der elektrischen Einrichtung.

```{r}
house_train <- house_train %>% 
  mutate(PoolQC = recode(PoolQC, .missing = "no pool"),
         Alley = recode(Alley, .missing = "no alley"),
         GarageQual = recode(GarageQual, .missing = "no garage"),
         GarageCond = recode(GarageCond, .missing = "no garage"))

house_predict <- house_predict %>% 
  mutate(PoolQC = recode(PoolQC, .missing = "no pool"),
         Alley = recode(Alley, .missing = "no alley"),
         GarageQual = recode(GarageQual, .missing = "no garage"),
         GarageCond = recode(GarageCond, .missing = "no garage"))
```

## Zielvariable
```{r}
ggplot(house_train, aes(SalePrice)) +
  geom_density()
```

Die Zielvariable ist nicht normalverteilt, die Vorhersage würde vermutlich durch
eine Transformation profitieren.

```{r}
ggplot(house_train, aes(SalePrice)) +
  geom_density() +
  scale_x_log10()
```

Die Logarithmierung verbessert die Verteilung. Möglicherweise wäre eine 
Transformation nach Box-Cox (mit einem $\lambda$ parameter < 0) besser geeignet,
aus Gründen der Einfachheit wird aber darauf verzichtet.


## Zusammenhang zwischen Prädiktoren und Zielvariable
Um die Zusammenhänge zu untersuchen werden zwei Grafiken definiert, eine für
kategoriale Prädiktoren (violin plot + scatter), eine für metrische Variablen 
(Scatterplot).

```{r}
compare_cat <- function(var, df = house_train) {
  var <- enquo(var)
  
  ggplot(df, aes(y = SalePrice, x = as.factor(!!var))) +
    geom_violin(adjust = .6, draw_quantiles = c(.25, .5, .75)) +
    geom_jitter(width = .1, alpha = .1)
}

compare_cont <- function(var, df = house_train) {
  
  cor <- summarise(df, cor(SalePrice, {{var}}, use = "pairwise.complete.obs")) %>% 
    as.numeric()
  
  cor <- glue::glue("cor = {format(cor, digits = 2)}")
  
  position <- df %>% 
    summarise(x_pos = max({{var}}, na.rm = T) - 
                (max({{var}}, na.rm = T) - min({{var}}, na.rm = T)) * .1,
           y_pos = max(SalePrice) - max(SalePrice) * .1)
  
  var <- enquo(var)
  
  ggplot(df, aes(y = SalePrice, x = !!var)) +
    geom_jitter() +
    geom_smooth() +
    annotate("text", label = cor, x = position$x_pos, y = position$y_pos)
  
}
```


```{r}
compare_cat(MSSubClass)
```


Die folgenden Grafiken dienen dazu zu entscheiden, ob eine Variable ins Modell
aufgenommen werden soll, und ob Transformationen notwendig sind. Sofern kein 
Kommentar zur Grafik erfolgt wird die Variable so wie sie ist ins Modell 
aufgenommen.


```{r}
compare_cat(MSZoning)
```


```{r}
compare_cont(LotFrontage)
```

```{r}
compare_cont(log(LotArea))
```

Der Zusammenhang wird besser modelliert, wenn von LotArea der log genommen wird.
Nachdem es Strukturbrüche gibt wäre es vermutlich hilfreich splines zu verwenden.

```{r}
compare_cat(Street)
```

Die Variable wird nicht aufgenommen.


```{r}
compare_cat(Alley)
```

```{r}
compare_cat(LotShape)
```

```{r}
compare_cat(LandContour)
```

```{r}
compare_cat(Utilities)
```


```{r}
compare_cat(LotConfig)
```

```{r}
compare_cat(LandSlope)
```

```{r}
compare_cat(Condition)
```

```{r}
compare_cat(BldgType)
```


```{r}
compare_cont(OverallQual)
```

```{r}
compare_cont(OverallCond)
```

```{r}
compare_cont(YearBuilt)
```

Hier scheint ein quadratischer Term angebracht.

```{r}
compare_cont(YearRemodAdd)
```

```{r}
compare_cat(RoofStyle)
```


```{r}
compare_cat(RoofMatl)
```

Die Variablen zum Dach haben nur wenige Werte in den jeweils schwächer besetzten
Kategorien und werden daher weggelassen.


```{r}
compare_cat(MasVnrType)
```

```{r}
compare_cont(MasVnrArea)
```

```{r}
compare_cat(ExterQual)
```

```{r}
compare_cat(ExterCond)
```

```{r}
compare_cont(TotalBsmtSF)
```

```{r}
compare_cat(Heating)
```

```{r}
compare_cat(HeatingQC)
```


```{r}
compare_cat(CentralAir)
```

```{r}
compare_cat(Electrical)
```


```{r}
compare_cont(X1stFlrSF)
```

```{r}
compare_cont(X2ndFlrSF)
```

```{r}
compare_cont(LowQualFinSF)
```

Diese Variable wird nicht aufgenommen.


```{r}
compare_cont(GrLivArea)
```

```{r}
compare_cat(BsmtFullBath)
```

Diese Variable wird als Dummy codiert.

```{r}
compare_cat(BsmtHalfBath)
```
Diese ebenso.

```{r}
compare_cat(FullBath)
```
```{r}
compare_cat(HalfBath)
```

```{r}
compare_cat(BedroomAbvGr)
```
Referenzkategorie: 3
```{r}
compare_cat(KitchenAbvGr)
```

Referenzkategorie: 1

```{r}
compare_cont(TotRmsAbvGrd)
```
```{r}
compare_cont(Fireplaces)
```

```{r}
compare_cont(GarageCars)
```

```{r}
compare_cont(GarageArea)
```

```{r}
compare_cat(GarageQual)
```

Ref: TA

```{r}
compare_cat(GarageCond)
```
Ref: TA


```{r}
compare_cat(PavedDrive)
```

```{r}
compare_cont(WoodDeckSF)
```


```{r}
compare_cont(OpenPorchSF)
```

```{r}
compare_cont(EnclosedPorch)
```
Diese Variable wird nicht verwendet (geringe Korrelation).

```{r}
compare_cont(X3SsnPorch)
```
Diese wird auch nicht verwendet.

```{r}
compare_cont(ScreenPorch)
```
Diese auch nicht.

```{r}
compare_cont(PoolArea)
```

```{r}
compare_cat(PoolQC)
```

Die Variablen zum Pool sind wenig aussagekräftig aufgrund einer geringen Fallzahl
und werden daher nicht verwendet.

```{r}
compare_cat(MoSold)
```

Diese Variable wird nicht verwendet

```{r}
compare_cont(YrSold)
```
Auch diese Variable wird nicht verwendet.

# Lineares Modell
```{r}
set.seed(12345)
ctrl <- trainControl(method = "repeatedcv", repeats = 5)

lm_fit1 <- train(
  log(SalePrice) ~ log(LotArea) + OverallQual,
  data = house_train,
  method = "lm",
  preProc = c("center", "scale", "knnImpute"),
  trControl = ctrl
)

lm_fit2 <- train(
  log(SalePrice) ~ log(LotArea) + OverallQual + CentralAir + MSSubClass + MSZoning +
       Alley + LotShape + YearBuilt + GarageQual,
  data = house_train,
  method = "lm",
  preProc = c("center", "scale", "knnImpute"),
  trControl = ctrl
)
```





# Lasso
```{r}
set.seed(12345)
ctrl <- trainControl(method = "repeatedcv", repeats = 5)

lambda <- 10^seq(-3, 3, length = 100)

lasso <- train(
  log(SalePrice) ~ log(LotArea) + OverallQual + CentralAir + MSSubClass + MSZoning +
       Alley + LotShape + YearBuilt + GarageQual,
  data = house_train,
  method = "glmnet",
  preProc = c("center", "scale", "knnImpute"),
  trControl = ctrl,
  tuneGrid = expand.grid(alpha = 0, lambda = lambda)
)
```


# Elastic Net
```{r}
set.seed(12345)
ctrl <- trainControl(method = "repeatedcv", repeats = 5)

enet <- train(
  log(SalePrice) ~ log(LotArea) + OverallQual + CentralAir + MSSubClass + MSZoning +
       Alley + LotShape + YearBuilt + GarageQual,
  data = house_train,
  method = "glmnet",
  preProc = c("center", "scale", "knnImpute"),
  trControl = ctrl,
  tuneLength = 10
)
```


# Modelle Vergleichen
```{r}
res <- resamples(list(lm1 = lm_fit1, lm2 = lm_fit2, lasso = lasso, enet = enet))
summary(res)
```

